{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План\n",
    "\n",
    "1. Разбиваем весь текст на токены-слова\n",
    "2. Удаляем стоп-слова. Местоимения и артикли в исключения\n",
    "2. Приводим все к нижнему регистру\n",
    "3. Уникализируем и подсчитываем количество каждого слова\n",
    "4. Создаем df\n",
    "4. К каждому слову добавляем столько раз предложение, сколько это слово встречается.\n",
    "5. Определяем часть речи и добавляем в df\n",
    "6. Если слово - глагол, что находим его 3 формы и списком добавляем в df. Проделываем эти операции со всеми частями речи по условию if\n",
    "Если артикль, то добавляем этим атриклям в df список всех артиклей (для выбора)\n",
    "\n",
    "\n",
    "### Виды упражнений\n",
    "1. Определить правильный артикль\n",
    "2. Определяем пропущенное слово\n",
    "3. Определить правильную форму глагола. Ищем в предложении все глаголы и предлагаем 3 формы. Не, не пойдет. Времен больше намного\n",
    "4. Расставить слова в правильном порядке. Перемешиваем все и даем выбрать\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:56:32.737724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to /Users/Sergey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pyinflect\n",
    "import random     \n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from googletrans import Translator\n",
    "\n",
    "\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем константой типы заданий\n",
    "\n",
    "TASKS = ['Выберите слово', 'Заполните пропуск']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем каждое предложение в отдельную строку df. Ставим сепоратор таб, иначе запятая выдает ошибку\n",
    "df = pd.read_csv('Little_Red_Cap_ Jacob_and_Wilhelm_Grimm.txt', lineterminator = '\\n', header=None, sep=\"\\t\", names=['origin_sentences'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Little_Red_Cap_ Jacob_and_Wilhelm_Grimm.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "#text = text.replace('\\n','')\n",
    "text = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Создаем датаврейм с каждым словом\n",
    "# df_all_words = pd.DataFrame({'origin_word':nltk.word_tokenize(lines)})\n",
    "# df_all_words.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once upon a time there was a sweet little girl. Everyone who saw her liked her, but most of all her grandmother, who did not know what to give the child next. Once she gave her a little cap made of red velvet. Because it suited her so well, and she wanted to wear it all the time, she came to be known as Little Red Cap.',\n",
       " 'One day her mother said to her, \"Come Little Red Cap. Here is a piece of cake and a bottle of wine. Take them to your grandmother. She is sick and weak, and they will do her well. Mind your manners and give her my greetings. Behave yourself on the way, and do not leave the path, or you might fall down and break the glass, and then there will be nothing for your sick grandmother.\"',\n",
       " '',\n",
       " 'Little Red Cap promised to obey her mother. The grandmother lived out in the woods, a half hour from the village. When Little Red Cap entered the woods a wolf came up to her. She did not know what a wicked animal he was, and was not afraid of him.',\n",
       " '',\n",
       " '\"Good day to you, Little Red Cap.\"',\n",
       " '',\n",
       " '\"Thank you, wolf.\"',\n",
       " '',\n",
       " '\"Where are you going so early, Little Red Cap?\"',\n",
       " '',\n",
       " '\"To grandmother\\'s.\"',\n",
       " '',\n",
       " '\"And what are you carrying under your apron?\"',\n",
       " '',\n",
       " '\"Grandmother is sick and weak, and I am taking her some cake and wine. We baked yesterday, and they should give her strength.\"',\n",
       " '',\n",
       " '\"Little Red Cap, just where does your grandmother live?\"',\n",
       " '',\n",
       " '\"Her house is a good quarter hour from here in the woods, under the three large oak trees. There\\'s a hedge of hazel bushes there. You must know the place,\" said Little Red Cap.',\n",
       " '',\n",
       " 'The wolf thought to himself, \"Now there is a tasty bite for me. Just how are you going to catch her?\" Then he said, \"Listen, Little Red Cap, haven\\'t you seen the beautiful flowers that are blossoming in the woods? Why don\\'t you go and take a look? And I don\\'t believe you can hear how beautifully the birds are singing. You are walking along as though you were on your way to school in the village. It is very beautiful in the woods.\"',\n",
       " '',\n",
       " 'Little Red Cap opened her eyes and saw the sunlight breaking through the trees and how the ground was covered with beautiful flowers. She thought, \"If a take a bouquet to grandmother, she will be very pleased. Anyway, it is still early, and I\\'ll be home on time.\" And she ran off into the woods looking for flowers. Each time she picked one she thought that she could see an even more beautiful one a little way off, and she ran after it, going further and further into the woods. But the wolf ran straight to the grandmother\\'s house and knocked on the door.',\n",
       " '',\n",
       " '\"Who\\'s there?\"',\n",
       " '',\n",
       " '\"Little Red Cap. I\\'m bringing you some cake and wine. Open the door for me.\"',\n",
       " '',\n",
       " '\"Just press the latch,\" called out the grandmother. \"I\\'m too weak to get up.\"',\n",
       " '',\n",
       " \"The wolf pressed the latch, and the door opened. He stepped inside, went straight to the grandmother's bed, and ate her up. Then he took her clothes, put them on, and put her cap on his head. He got into her bed and pulled the curtains shut.\",\n",
       " '',\n",
       " 'Little Red Cap had run after flowers, and did not continue on her way to grandmother\\'s until she had gathered all that she could carry. When she arrived, she found, to her surprise, that the door was open. She walked into the parlor, and everything looked so strange that she thought, \"Oh, my God, why am I so afraid? I usually like it at grandmother\\'s.\" Then she went to the bed and pulled back the curtains. Grandmother was lying there with her cap pulled down over her face and looking very strange.',\n",
       " '',\n",
       " '\"Oh, grandmother, what big ears you have!\"',\n",
       " '',\n",
       " '\"All the better to hear you with.\"',\n",
       " '',\n",
       " '\"Oh, grandmother, what big eyes you have!\"',\n",
       " '',\n",
       " '\"All the better to see you with.\"',\n",
       " '',\n",
       " '\"Oh, grandmother, what big hands you have!\"',\n",
       " '',\n",
       " '\"All the better to grab you with!\"',\n",
       " '',\n",
       " '\"Oh, grandmother, what a horribly big mouth you have!\"',\n",
       " '',\n",
       " '\"All the better to eat you with!\" And with that he jumped out of bed, jumped on top of poor Little Red Cap, and ate her up. As soon as the wolf had finished this tasty bite, he climbed back into bed, fell asleep, and began to snore very loudly.',\n",
       " '',\n",
       " 'A huntsman was just passing by. He thought it strange that the old woman was snoring so loudly, so he decided to take a look. He stepped inside, and in the bed there lay the wolf that he had been hunting for such a long time. \"He has eaten the grandmother, but perhaps she still can be saved. I won\\'t shoot him,\" thought the huntsman. So he took a pair of scissors and cut open his belly.',\n",
       " '',\n",
       " 'He had cut only a few strokes when he saw the red cap shining through. He cut a little more, and the girl jumped out and cried, \"Oh, I was so frightened! It was so dark inside the wolf\\'s body!\"',\n",
       " '',\n",
       " \"And then the grandmother came out alive as well. Then Little Red Cap fetched some large heavy stones. They filled the wolf's body with them, and when he woke up and tried to run away, the stones were so heavy that he fell down dead.\",\n",
       " '',\n",
       " 'The three of them were happy. The huntsman took the wolf\\'s pelt. The grandmother ate the cake and drank the wine that Little Red Cap had brought. And Little Red Cap thought to herself, \"As long as I live, I will never leave the path and run off into the woods by myself if mother tells me not to.\"',\n",
       " '',\n",
       " 'They also tell how Little Red Cap was taking some baked things to her grandmother another time, when another wolf spoke to her and wanted her to leave the path. But Little Red Cap took care and went straight to grandmother\\'s. She told her that she had seen the wolf, and that he had wished her a good day, but had stared at her in a wicked manner. \"If we hadn\\'t been on a public road, he would have eaten me up,\" she said.',\n",
       " '',\n",
       " '\"Come,\" said the grandmother. \"Let\\'s lock the door, so he can\\'t get in.\"',\n",
       " '',\n",
       " 'Soon afterward the wolf knocked on the door and called out, \"Open up, grandmother. It\\'s Little Red Cap, and I\\'m bringing you some baked things.\"',\n",
       " '',\n",
       " 'They remained silent, and did not open the door. The wicked one walked around the house several times, and finally jumped onto the roof. He wanted to wait until Little Red Cap went home that evening, then follow her and eat her up in the darkness. But the grandmother saw what he was up to. There was a large stone trough in front of the house.',\n",
       " '',\n",
       " '\"Fetch a bucket, Little Red Cap,\" she said. \"Yesterday I cooked some sausage. Carry the water that I boiled them with to the trough.\" Little Red Cap carried water until the large, large trough was clear full. The smell of sausage arose into the wolf\\'s nose. He sniffed and looked down, stretching his neck so long that he could no longer hold himself, and he began to slide. He slid off the roof, fell into the trough, and drowned. And Little Red Cap returned home happily and safely.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'textx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m texts \u001b[39m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNet income was $9.4 million compared to the prior year of $2.7 million.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRevenue exceeded twelve billion dollars, with a loss of $1b.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m nlp\u001b[39m.\u001b[39mpipe(textx, disable\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtok2vec\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtagger\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mparser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mattribute_ruler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlemmatizer\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m     10\u001b[0m     \u001b[39m# Do something with the doc here\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m([(ent\u001b[39m.\u001b[39mtext, ent\u001b[39m.\u001b[39mlabel_) \u001b[39mfor\u001b[39;00m ent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'textx' is not defined"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "texts = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for doc in nlp.pipe(text, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    # Do something with the doc here\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(df['origin_sentences'].astype('unicode').values, batch_size=50,\n",
    "                        ):\n",
    "    if doc.is_parsed:\n",
    "        tokens.append([n.text for n in doc])\n",
    "        lemma.append([n.lemma_ for n in doc])\n",
    "        pos.append([n.pos_ for n in doc])\n",
    "        \n",
    "    else:\n",
    "        # We want to make sure that the lists of parsed results have the\n",
    "        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
    "        tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "\n",
    "df['word_tokens'] = tokens\n",
    "df['word_lemma'] = lemma\n",
    "df['word_pos'] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyinflect\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens = nlp('This is an example of xxtest.')\n",
    "tokens[3]._.inflect('NNS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# изменение степени прилагательного с помощью pyinflect\n",
    "for token in nlp(\"I think it's a good idea and easy to use\"):\n",
    "    if word_pos=='ADJ':\n",
    "        print(token.text, token._.inflect('JJS'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = 'ADJ'\n",
    "for i in df.word_pos:\n",
    "   \n",
    "    if item in i:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ADJ'.isin(df.word_pos):\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df[\"ADJ_forms\"] = df.apply(lambda x: int(x[\"ride_cost\"] * 0.95)\n",
    "                                 if x[\"rating\"] > 6 and x[\"speed_max\"] < 120\n",
    "                                 else int(x[\"ride_cost\"] * 1.05),\n",
    "                                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in df_all_words.origin_word:\n",
    "    print('lemma:', word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим слова к начальной форме (лемме)\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(df['origin_sentences'].astype('unicode').values)\n",
    "\n",
    "token = doc\n",
    "print(token.text)\n",
    "for word in doc:\n",
    "    print('lemma:', word.lemma_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизируем каждо\n",
    "\n",
    "df['bag_of_words'] = df.origin_sentences.apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "#result2 = df.assign(feature_1=df.apply(nltk.word_tokenize(\"a house word \")))\n",
    "\n",
    "#bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame({'origin_words':bag_of_words})\n",
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Этот код ищет словоформы, но только существвительные\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "forms = set() #We'll store the derivational forms in a set to eliminate duplicates\n",
    "for happy_lemma in wn.lemmas(\"like\"): #for each \"happy\" lemma in WordNet\n",
    "    forms.add(happy_lemma.name()) #add the lemma itself\n",
    "    for related_lemma in happy_lemma.derivationally_related_forms(): #for each related lemma\n",
    "        forms.add(related_lemma.name()) #add the related lemma\n",
    "forms        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_sens = nltk.tokenize.sent_tokenize(text, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_sentences = pd.DataFrame({'sentence': tokens_sens})\n",
    "df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Language.component(\"segm\")\n",
    "# def set_custom_segmentation(doc):\n",
    "#     for token in doc[:-1]:\n",
    "#         if token.text == '{S}':\n",
    "#             doc[token.i+1].is_sent_start = True\n",
    "#         else:\n",
    "#             doc[token.i+1].is_sent_start = False\n",
    "#     return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#from spacy.lang.ru import Russian\n",
    "#from spacy import displacy\n",
    "#from spacy.lang.en.examples import sentences \n",
    "\n",
    "#import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp('''\n",
    "Once upon a time there was a sweet little girl. Everyone who saw her liked her, but most of all her grandmother, who did not know what to give the child next. Once she gave her a little cap made of red velvet. Because it suited her so well, and she wanted to wear it all the time, she came to be known as Little Red Cap.\n",
    "One day her mother said to her, \"Come Little Red Cap. Here is a piece of cake and a bottle of wine. Take them to your grandmother. She is sick and weak, and they will do her well. Mind your manners and give her my greetings. Behave yourself on the way, and do not leave the path, or you might fall down and break the glass, and then there will be nothing for your sick grandmother.\"\n",
    "\n",
    "Little Red Cap promised to obey her mother. The grandmother lived out in the woods, a half hour from the village. When Little Red Cap entered the woods a wolf came up to her. She did not know what a wicked animal he was, and was not afraid of him.\n",
    "\n",
    "\"Good day to you, Little Red Cap.\"\n",
    "\n",
    "\"Thank you, wolf.\"\n",
    "\n",
    "\"Where are you going so early, Little Red Cap?\"\n",
    "\n",
    "\"To grandmother's.\"\n",
    "\n",
    "\"And what are you carrying under your apron?\"\n",
    "''')\n",
    "#open('Little_Red_Cap_ Jacob_and_Wilhelm_Grimm.txt', encoding ='utf-8')\n",
    "i=0\n",
    "for sent in doc.sents:\n",
    "    i+=1\n",
    "    print('i=', str(i)+sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = doc\n",
    "print(token.text)\n",
    "for word in doc:\n",
    "    print('lemma:', word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Russian()\n",
    "doc = nlp(\"Съешь ещё этих мягких французских булок, да выпей чаю.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = doc[0]\n",
    "print(token.text)\n",
    "\n",
    "span = doc[3:6]\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"is_alpha:    \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:    \", [token.is_punct for token in doc])\n",
    "print(\"like_num:    \", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "  \n",
    "#  прочитать текстовый файл как объект\n",
    "doc = open('Little_Red_Cap_ Jacob_and_Wilhelm_Grimm.txt', encoding ='utf-8')\n",
    "  \n",
    "# предварительная обработка файла для получения списка токенов\n",
    "tokenized = []\n",
    "for sentence in doc.read().split('.'):\n",
    "    # функция simple_preprocess возвращает список слов каждого предложения\n",
    "    tokenized.append(simple_preprocess(sentence, deacc = True))\n",
    "  \n",
    "for i in tokenized:\n",
    "    print(i)\n",
    "doc.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyinflect чтобы изменять слова (времена глагола, степени прилагательных, число множ/ед)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyinflect\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens = nlp('This is an example of xxtest.')\n",
    "tokens[3]._.inflect('NNS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokens)):\n",
    "    # тут условие if проверка на часть речи\n",
    "    for j in range(0, 3):\n",
    "        print(tokens[i]._.inflect('VBD', form_num=j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[1]._.inflect('VBD', form_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[5]._.inflect('VBG', inflect_oov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of word (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsentences = [\"Joe waited for the train train\", \"The train was late\", \"Mary and Samantha took the bus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(allsentences)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences.sentence.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 18:03:59.503137: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import transformers\n",
    "#from tensorflow.python.keras.models import transformers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from pymystem3 import Mystem\n",
    "from tqdm.notebook import tqdm\n",
    "from wordcloud import WordCloud\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Little Red Cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jacob and Wilhelm Grimm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time there was a sweet little girl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One day her mother said to her, \"Come Little R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Red Cap promised to obey her mother. Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    origin_sentences\n",
       "0                                     Little Red Cap\n",
       "1                            Jacob and Wilhelm Grimm\n",
       "2  Once upon a time there was a sweet little girl...\n",
       "3  One day her mother said to her, \"Come Little R...\n",
       "4  Little Red Cap promised to obey her mother. Th..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем каждое предложение в отдельную строку df. Ставим сепоратор таб, иначе запятая выдает ошибку\n",
    "df = pd.read_csv('Little_Red_Cap_ Jacob_and_Wilhelm_Grimm.txt', lineterminator = '\\n', header=None, sep=\"\\t\", names=['origin_sentences'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Once upon a time there was a sweet little girl. Everyone who saw her liked her, but most of all her grandmother, who did not know what to give the child next. Once she gave her a little cap made of red velvet. Because it suited her so well, and she wanted to wear it all the time, she came to be known as Little Red Cap.\n",
    "One day her mother said to her, \"Come Little Red Cap. Here is a piece of cake and a bottle of wine. Take them to your grandmother. She is sick and weak, and they will do her well. Mind your manners and give her my greetings. Behave yourself on the way, and do not leave the path, or you might fall down and break the glass, and then there will be nothing for your sick grandmother.\"\n",
    "\n",
    "Little Red Cap promised to obey her mother. The grandmother lived out in the woods, a half hour from the village. When Little Red Cap entered the woods a wolf came up to her. She did not know what a wicked animal he was, and was not afraid of him.\n",
    "\n",
    "\"Good day to you, Little Red Cap.\"\n",
    "\n",
    "\"Thank you, wolf.\"\n",
    "\n",
    "\"Where are you going so early, Little Red Cap?\"\n",
    "\n",
    "\"To grandmother's.\"\n",
    "\n",
    "\"And what are you carrying under your apron?\"\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'they', \"won't\", 'have', 'don', 'each', 'themselves', 'theirs', 'its', 'between', 'when', 'up', 'under', 'just', \"shan't\", 'again', 'here', \"weren't\", 'so', 'was', 'couldn', 'hasn', 'm', 'do', 'to', 'an', 'ain', 'it', 'these', 'were', 'own', 'is', 'been', 'y', \"shouldn't\", 'herself', 'such', 'nor', 'will', 'now', 'o', \"isn't\", 'didn', 'be', 'this', 'wouldn', 'his', 'my', 'i', 're', \"mustn't\", 'from', 'had', \"couldn't\", 'while', 'haven', \"you'll\", 'them', 'below', 'where', 'll', \"didn't\", 'a', 'her', 'about', 'any', 'isn', 'needn', 'in', \"you've\", 'your', 'our', 'against', 'too', 'shouldn', 'won', 'both', 'him', 'who', 'after', \"you're\", 'am', 'has', 'weren', 'myself', \"haven't\", 'are', 'off', 'once', 't', 'doesn', 'yourselves', \"needn't\", 'should', \"hadn't\", 'whom', \"wasn't\", \"mightn't\", 'on', 'than', 've', 'but', 'more', 'through', \"aren't\", 'other', 'by', 'above', 'hadn', 'and', 'doing', 'we', \"hasn't\", 'did', 'of', 'how', \"doesn't\", 'during', 'into', 'before', 'ours', 'aren', 'you', \"she's\", 'itself', 'because', 'd', \"don't\", 'over', \"it's\", 'only', 's', 'down', 'ma', \"wouldn't\", \"that'll\", \"should've\", 'why', 'if', 'as', 'out', 'yours', 'himself', 'until', 'there', 'all', 'can', 'having', 'at', 'most', 'those', 'few', 'mightn', 'which', 'yourself', 'not', 'or', 'hers', 'mustn', 'some', 'wasn', 'he', 'with', 'for', \"you'd\", 'ourselves', 'does', 'their', 'the', 'shan', 'she', 'that', 'then', 'no', 'very', 'what', 'same', 'further', 'me', 'being'}\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once',\n",
       " 'upon',\n",
       " 'a',\n",
       " 'time',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'sweet',\n",
       " 'little',\n",
       " 'girl',\n",
       " '.',\n",
       " 'Everyone',\n",
       " 'who',\n",
       " 'saw',\n",
       " 'her',\n",
       " 'liked',\n",
       " 'her',\n",
       " ',',\n",
       " 'but',\n",
       " 'most',\n",
       " 'of',\n",
       " 'all',\n",
       " 'her',\n",
       " 'grandmother',\n",
       " ',',\n",
       " 'who',\n",
       " 'did',\n",
       " 'not',\n",
       " 'know',\n",
       " 'what',\n",
       " 'to',\n",
       " 'give',\n",
       " 'the',\n",
       " 'child',\n",
       " 'next',\n",
       " '.',\n",
       " 'Once',\n",
       " 'she',\n",
       " 'gave',\n",
       " 'her',\n",
       " 'a',\n",
       " 'little',\n",
       " 'cap',\n",
       " 'made',\n",
       " 'of',\n",
       " 'red',\n",
       " 'velvet',\n",
       " '.',\n",
       " 'Because',\n",
       " 'it',\n",
       " 'suited',\n",
       " 'her',\n",
       " 'so',\n",
       " 'well',\n",
       " ',',\n",
       " 'and',\n",
       " 'she',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'wear',\n",
       " 'it',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " ',',\n",
       " 'she',\n",
       " 'came',\n",
       " 'to',\n",
       " 'be',\n",
       " 'known',\n",
       " 'as',\n",
       " 'Little',\n",
       " 'Red',\n",
       " 'Cap',\n",
       " '.',\n",
       " 'One',\n",
       " 'day',\n",
       " 'her',\n",
       " 'mother',\n",
       " 'said',\n",
       " 'to',\n",
       " 'her',\n",
       " ',',\n",
       " '``',\n",
       " 'Come',\n",
       " 'Little',\n",
       " 'Red',\n",
       " 'Cap',\n",
       " '.',\n",
       " 'Here',\n",
       " 'is',\n",
       " 'a',\n",
       " 'piece',\n",
       " 'of',\n",
       " 'cake',\n",
       " 'and',\n",
       " 'a',\n",
       " 'bottle',\n",
       " 'of',\n",
       " 'wine',\n",
       " '.',\n",
       " 'Take',\n",
       " 'them',\n",
       " 'to',\n",
       " 'your',\n",
       " 'grandmother',\n",
       " '.',\n",
       " 'She',\n",
       " 'is',\n",
       " 'sick',\n",
       " 'and',\n",
       " 'weak',\n",
       " ',',\n",
       " 'and',\n",
       " 'they',\n",
       " 'will',\n",
       " 'do',\n",
       " 'her',\n",
       " 'well',\n",
       " '.',\n",
       " 'Mind',\n",
       " 'your',\n",
       " 'manners',\n",
       " 'and',\n",
       " 'give',\n",
       " 'her',\n",
       " 'my',\n",
       " 'greetings',\n",
       " '.',\n",
       " 'Behave',\n",
       " 'yourself',\n",
       " 'on',\n",
       " 'the',\n",
       " 'way',\n",
       " ',',\n",
       " 'and',\n",
       " 'do',\n",
       " 'not',\n",
       " 'leave',\n",
       " 'the',\n",
       " 'path',\n",
       " ',',\n",
       " 'or',\n",
       " 'you',\n",
       " 'might',\n",
       " 'fall',\n",
       " 'down',\n",
       " 'and',\n",
       " 'break',\n",
       " 'the',\n",
       " 'glass',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'nothing',\n",
       " 'for',\n",
       " 'your',\n",
       " 'sick',\n",
       " 'grandmother',\n",
       " '.',\n",
       " \"''\",\n",
       " 'Little',\n",
       " 'Red',\n",
       " 'Cap',\n",
       " 'promised',\n",
       " 'to',\n",
       " 'obey',\n",
       " 'her',\n",
       " 'mother',\n",
       " '.',\n",
       " 'The',\n",
       " 'grandmother',\n",
       " 'lived',\n",
       " 'out',\n",
       " 'in',\n",
       " 'the',\n",
       " 'woods',\n",
       " ',',\n",
       " 'a',\n",
       " 'half',\n",
       " 'hour',\n",
       " 'from',\n",
       " 'the',\n",
       " 'village',\n",
       " '.',\n",
       " 'When',\n",
       " 'Little',\n",
       " 'Red',\n",
       " 'Cap',\n",
       " 'entered',\n",
       " 'the',\n",
       " 'woods',\n",
       " 'a',\n",
       " 'wolf',\n",
       " 'came',\n",
       " 'up',\n",
       " 'to',\n",
       " 'her',\n",
       " '.',\n",
       " 'She',\n",
       " 'did',\n",
       " 'not',\n",
       " 'know',\n",
       " 'what',\n",
       " 'a',\n",
       " 'wicked',\n",
       " 'animal',\n",
       " 'he',\n",
       " 'was',\n",
       " ',',\n",
       " 'and',\n",
       " 'was',\n",
       " 'not',\n",
       " 'afraid',\n",
       " 'of',\n",
       " 'him',\n",
       " '.',\n",
       " '``',\n",
       " 'Good',\n",
       " 'day',\n",
       " 'to',\n",
       " 'you',\n",
       " ',',\n",
       " 'Little',\n",
       " 'Red',\n",
       " 'Cap',\n",
       " '.',\n",
       " \"''\",\n",
       " '``',\n",
       " 'Thank',\n",
       " 'you',\n",
       " ',',\n",
       " 'wolf',\n",
       " '.',\n",
       " \"''\",\n",
       " '``',\n",
       " 'Where',\n",
       " 'are',\n",
       " 'you',\n",
       " 'going',\n",
       " 'so',\n",
       " 'early',\n",
       " ',',\n",
       " 'Little',\n",
       " 'Red',\n",
       " 'Cap',\n",
       " '?',\n",
       " \"''\",\n",
       " '``',\n",
       " 'To',\n",
       " 'grandmother',\n",
       " \"'s\",\n",
       " '.',\n",
       " \"''\",\n",
       " '``',\n",
       " 'And',\n",
       " 'what',\n",
       " 'are',\n",
       " 'you',\n",
       " 'carrying',\n",
       " 'under',\n",
       " 'your',\n",
       " 'apron',\n",
       " '?',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All words\n",
    "\n",
    "bag_of_words = nltk.word_tokenize(text)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'likable', 'like', 'likeable', 'likeness'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Этот код ищет словоформы, но только существвительные\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "forms = set() #We'll store the derivational forms in a set to eliminate duplicates\n",
    "for happy_lemma in wn.lemmas(\"like\"): #for each \"happy\" lemma in WordNet\n",
    "    forms.add(happy_lemma.name()) #add the lemma itself\n",
    "    for related_lemma in happy_lemma.derivationally_related_forms(): #for each related lemma\n",
    "        forms.add(related_lemma.name()) #add the related lemma\n",
    "forms        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_sens = nltk.tokenize.sent_tokenize(text, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time there was a sweet little girl.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everyone who saw her liked her, but most of all her grandmother, who did not know what to give the child next.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once she gave her a little cap made of red velvet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Because it suited her so well, and she wanted to wear it all the time, she came to be known as Little Red Cap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One day her mother said to her, \"Come Little Red Cap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here is a piece of cake and a bottle of wine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Take them to your grandmother.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>She is sick and weak, and they will do her well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mind your manners and give her my greetings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Behave yourself on the way, and do not leave the path, or you might fall down and break the glass, and then there will be nothing for your sick grandmother.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Little Red Cap promised to obey her mother.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The grandmother lived out in the woods, a half hour from the village.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When Little Red Cap entered the woods a wolf came up to her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>She did not know what a wicked animal he was, and was not afraid of him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Good day to you, Little Red Cap.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Thank you, wolf.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Where are you going so early, Little Red Cap?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"To grandmother's.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"And what are you carrying under your apron?\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         sentence\n",
       "0                                                                                                                 Once upon a time there was a sweet little girl.\n",
       "1                                                  Everyone who saw her liked her, but most of all her grandmother, who did not know what to give the child next.\n",
       "2                                                                                                              Once she gave her a little cap made of red velvet.\n",
       "3                                                  Because it suited her so well, and she wanted to wear it all the time, she came to be known as Little Red Cap.\n",
       "4                                                                                                           One day her mother said to her, \"Come Little Red Cap.\n",
       "5                                                                                                                   Here is a piece of cake and a bottle of wine.\n",
       "6                                                                                                                                  Take them to your grandmother.\n",
       "7                                                                                                                She is sick and weak, and they will do her well.\n",
       "8                                                                                                                    Mind your manners and give her my greetings.\n",
       "9   Behave yourself on the way, and do not leave the path, or you might fall down and break the glass, and then there will be nothing for your sick grandmother.\"\n",
       "10                                                                                                                    Little Red Cap promised to obey her mother.\n",
       "11                                                                                          The grandmother lived out in the woods, a half hour from the village.\n",
       "12                                                                                                   When Little Red Cap entered the woods a wolf came up to her.\n",
       "13                                                                                       She did not know what a wicked animal he was, and was not afraid of him.\n",
       "14                                                                                                                             \"Good day to you, Little Red Cap.\"\n",
       "15                                                                                                                                             \"Thank you, wolf.\"\n",
       "16                                                                                                                \"Where are you going so early, Little Red Cap?\"\n",
       "17                                                                                                                                            \"To grandmother's.\"\n",
       "18                                                                                                                  \"And what are you carrying under your apron?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_sentences = pd.DataFrame({'sentence': tokens_sens})\n",
    "df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She did not know what a wicked animal he was, and was not afraid of him\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Language.component(\"segm\")\n",
    "# def set_custom_segmentation(doc):\n",
    "#     for token in doc[:-1]:\n",
    "#         if token.text == '{S}':\n",
    "#             doc[token.i+1].is_sent_start = True\n",
    "#         else:\n",
    "#             doc[token.i+1].is_sent_start = False\n",
    "#     return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1\n",
      "Once upon a time there was a sweet little girl.\n",
      "i= 2Everyone who saw her liked her, but most of all her grandmother, who did not know what to give the child next.\n",
      "i= 3Once she gave her a little cap made of red velvet.\n",
      "i= 4Because it suited her so well, and she wanted to wear it all the time, she came to be known as Little Red Cap.\n",
      "\n",
      "i= 5One day her mother said to her, \"Come Little Red Cap.\n",
      "i= 6Here is a piece of cake and a bottle of wine.\n",
      "i= 7Take them to your grandmother.\n",
      "i= 8She is sick and weak, and they will do her well.\n",
      "i= 9Mind your manners and give her my greetings.\n",
      "i= 10Behave yourself on the way, and do not leave the path, or you might fall down and break the glass, and then there will be nothing for your sick grandmother.\n",
      "i= 11\"\n",
      "\n",
      "Little Red Cap promised to obey her mother.\n",
      "i= 12The grandmother lived out in the woods, a half hour from the village.\n",
      "i= 13When Little Red Cap entered the woods a wolf came up to her.\n",
      "i= 14She did not know what a wicked animal he was, and was not afraid of him.\n",
      "\n",
      "\n",
      "i= 15\"Good day to you, Little Red Cap.\"\n",
      "\n",
      "\"Thank you, wolf.\n",
      "i= 16\"\n",
      "\n",
      "\"Where are you going so early, Little Red Cap?\"\n",
      "\n",
      "\"To grandmother's.\n",
      "i= 17\"\n",
      "\n",
      "\"And what are you carrying under your apron?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#from spacy.lang.ru import Russian\n",
    "#from spacy import displacy\n",
    "#from spacy.lang.en.examples import sentences \n",
    "\n",
    "#import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp('''\n",
    "Once upon a time there was a sweet little girl. Everyone who saw her liked her, but most of all her grandmother, who did not know what to give the child next. Once she gave her a little cap made of red velvet. Because it suited her so well, and she wanted to wear it all the time, she came to be known as Little Red Cap.\n",
    "One day her mother said to her, \"Come Little Red Cap. Here is a piece of cake and a bottle of wine. Take them to your grandmother. She is sick and weak, and they will do her well. Mind your manners and give her my greetings. Behave yourself on the way, and do not leave the path, or you might fall down and break the glass, and then there will be nothing for your sick grandmother.\"\n",
    "\n",
    "Little Red Cap promised to obey her mother. The grandmother lived out in the woods, a half hour from the village. When Little Red Cap entered the woods a wolf came up to her. She did not know what a wicked animal he was, and was not afraid of him.\n",
    "\n",
    "\"Good day to you, Little Red Cap.\"\n",
    "\n",
    "\"Thank you, wolf.\"\n",
    "\n",
    "\"Where are you going so early, Little Red Cap?\"\n",
    "\n",
    "\"To grandmother's.\"\n",
    "\n",
    "\"And what are you carrying under your apron?\"\n",
    "''')\n",
    "#open('Little_Red_Cap_ Jacob_and_Wilhelm_Grimm.txt', encoding ='utf-8')\n",
    "i=0\n",
    "for sent in doc.sents:\n",
    "    i+=1\n",
    "    print('i=', str(i)+sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She she PRON PRP nsubj Xxx True True\n",
      "did do AUX VBD aux xxx True True\n",
      "not not PART RB neg xxx True True\n",
      "know know VERB VB ROOT xxxx True False\n",
      "what what PRON WP det xxxx True True\n",
      "a a DET DT det x True True\n",
      "wicked wicked ADJ JJ amod xxxx True False\n",
      "animal animal NOUN NN npadvmod xxxx True False\n",
      "he he PRON PRP nsubj xx True True\n",
      "was be AUX VBD ccomp xxx True True\n",
      ", , PUNCT , punct , False False\n",
      "and and CCONJ CC cc xxx True True\n",
      "was be AUX VBD conj xxx True True\n",
      "not not PART RB neg xxx True True\n",
      "afraid afraid ADJ JJ acomp xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "him he PRON PRP pobj xxx True True\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"aacbdc9137a849c59032b1b6c616aa4a-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">New</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">MacBook</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">set</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">launch</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">tomorrow</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aacbdc9137a849c59032b1b6c616aa4a-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aacbdc9137a849c59032b1b6c616aa4a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aacbdc9137a849c59032b1b6c616aa4a-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aacbdc9137a849c59032b1b6c616aa4a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aacbdc9137a849c59032b1b6c616aa4a-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aacbdc9137a849c59032b1b6c616aa4a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aacbdc9137a849c59032b1b6c616aa4a-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aacbdc9137a849c59032b1b6c616aa4a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aacbdc9137a849c59032b1b6c616aa4a-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aacbdc9137a849c59032b1b6c616aa4a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She did not know what a wicked animal he was, and was not afraid of him\n",
      "lemma: she\n",
      "lemma: do\n",
      "lemma: not\n",
      "lemma: know\n",
      "lemma: what\n",
      "lemma: a\n",
      "lemma: wicked\n",
      "lemma: animal\n",
      "lemma: he\n",
      "lemma: be\n",
      "lemma: ,\n",
      "lemma: and\n",
      "lemma: be\n",
      "lemma: not\n",
      "lemma: afraid\n",
      "lemma: of\n",
      "lemma: he\n"
     ]
    }
   ],
   "source": [
    "token = doc\n",
    "print(token.text)\n",
    "for word in doc:\n",
    "    print('lemma:', word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Russian()\n",
    "doc = nlp(\"Съешь ещё этих мягких французских булок, да выпей чаю.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Съешь\n",
      "мягких французских булок\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "print(token.text)\n",
    "\n",
    "span = doc[3:6]\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_alpha:     [True, True, True, True, True, True, False, True, True, True, False]\n",
      "is_punct:     [False, False, False, False, False, False, True, False, False, False, True]\n",
      "like_num:     [False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(\"is_alpha:    \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:    \", [token.is_punct for token in doc])\n",
    "print(\"like_num:    \", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['little', 'red', 'cap', 'jacob', 'and', 'wilhelm', 'grimm', 'once', 'upon', 'time', 'there', 'was', 'sweet', 'little', 'girl']\n",
      "['everyone', 'who', 'saw', 'her', 'liked', 'her', 'but', 'most', 'of', 'all', 'her', 'grandmother', 'who', 'did', 'not', 'know', 'what', 'to', 'give', 'the', 'child', 'next']\n",
      "['once', 'she', 'gave', 'her', 'little', 'cap', 'made', 'of', 'red', 'velvet']\n",
      "['because', 'it', 'suited', 'her', 'so', 'well', 'and', 'she', 'wanted', 'to', 'wear', 'it', 'all', 'the', 'time', 'she', 'came', 'to', 'be', 'known', 'as', 'little', 'red', 'cap']\n",
      "['one', 'day', 'her', 'mother', 'said', 'to', 'her', 'come', 'little', 'red', 'cap']\n",
      "['here', 'is', 'piece', 'of', 'cake', 'and', 'bottle', 'of', 'wine']\n",
      "['take', 'them', 'to', 'your', 'grandmother']\n",
      "['she', 'is', 'sick', 'and', 'weak', 'and', 'they', 'will', 'do', 'her', 'well']\n",
      "['mind', 'your', 'manners', 'and', 'give', 'her', 'my', 'greetings']\n",
      "['behave', 'yourself', 'on', 'the', 'way', 'and', 'do', 'not', 'leave', 'the', 'path', 'or', 'you', 'might', 'fall', 'down', 'and', 'break', 'the', 'glass', 'and', 'then', 'there', 'will', 'be', 'nothing', 'for', 'your', 'sick', 'grandmother']\n",
      "['little', 'red', 'cap', 'promised', 'to', 'obey', 'her', 'mother']\n",
      "['the', 'grandmother', 'lived', 'out', 'in', 'the', 'woods', 'half', 'hour', 'from', 'the', 'village']\n",
      "['when', 'little', 'red', 'cap', 'entered', 'the', 'woods', 'wolf', 'came', 'up', 'to', 'her']\n",
      "['she', 'did', 'not', 'know', 'what', 'wicked', 'animal', 'he', 'was', 'and', 'was', 'not', 'afraid', 'of', 'him']\n",
      "['good', 'day', 'to', 'you', 'little', 'red', 'cap']\n",
      "['thank', 'you', 'wolf']\n",
      "['where', 'are', 'you', 'going', 'so', 'early', 'little', 'red', 'cap', 'to', 'grandmother']\n",
      "['and', 'what', 'are', 'you', 'carrying', 'under', 'your', 'apron', 'grandmother', 'is', 'sick', 'and', 'weak', 'and', 'am', 'taking', 'her', 'some', 'cake', 'and', 'wine']\n",
      "['we', 'baked', 'yesterday', 'and', 'they', 'should', 'give', 'her', 'strength']\n",
      "['little', 'red', 'cap', 'just', 'where', 'does', 'your', 'grandmother', 'live', 'her', 'house', 'is', 'good', 'quarter', 'hour', 'from', 'here', 'in', 'the', 'woods', 'under', 'the', 'three', 'large', 'oak', 'trees']\n",
      "['there', 'hedge', 'of', 'hazel', 'bushes', 'there']\n",
      "['you', 'must', 'know', 'the', 'place', 'said', 'little', 'red', 'cap']\n",
      "['the', 'wolf', 'thought', 'to', 'himself', 'now', 'there', 'is', 'tasty', 'bite', 'for', 'me']\n",
      "['just', 'how', 'are', 'you', 'going', 'to', 'catch', 'her', 'then', 'he', 'said', 'listen', 'little', 'red', 'cap', 'haven', 'you', 'seen', 'the', 'beautiful', 'flowers', 'that', 'are', 'blossoming', 'in', 'the', 'woods', 'why', 'don', 'you', 'go', 'and', 'take', 'look', 'and', 'don', 'believe', 'you', 'can', 'hear', 'how', 'beautifully', 'the', 'birds', 'are', 'singing']\n",
      "['you', 'are', 'walking', 'along', 'as', 'though', 'you', 'were', 'on', 'your', 'way', 'to', 'school', 'in', 'the', 'village']\n",
      "['it', 'is', 'very', 'beautiful', 'in', 'the', 'woods']\n",
      "['little', 'red', 'cap', 'opened', 'her', 'eyes', 'and', 'saw', 'the', 'sunlight', 'breaking', 'through', 'the', 'trees', 'and', 'how', 'the', 'ground', 'was', 'covered', 'with', 'beautiful', 'flowers']\n",
      "['she', 'thought', 'if', 'take', 'bouquet', 'to', 'grandmother', 'she', 'will', 'be', 'very', 'pleased']\n",
      "['anyway', 'it', 'is', 'still', 'early', 'and', 'll', 'be', 'home', 'on', 'time']\n",
      "['and', 'she', 'ran', 'off', 'into', 'the', 'woods', 'looking', 'for', 'flowers']\n",
      "['each', 'time', 'she', 'picked', 'one', 'she', 'thought', 'that', 'she', 'could', 'see', 'an', 'even', 'more', 'beautiful', 'one', 'little', 'way', 'off', 'and', 'she', 'ran', 'after', 'it', 'going', 'further', 'and', 'further', 'into', 'the', 'woods']\n",
      "['but', 'the', 'wolf', 'ran', 'straight', 'to', 'the', 'grandmother', 'house', 'and', 'knocked', 'on', 'the', 'door']\n",
      "['who', 'there', 'little', 'red', 'cap']\n",
      "['bringing', 'you', 'some', 'cake', 'and', 'wine']\n",
      "['open', 'the', 'door', 'for', 'me']\n",
      "['just', 'press', 'the', 'latch', 'called', 'out', 'the', 'grandmother']\n",
      "['too', 'weak', 'to', 'get', 'up']\n",
      "['the', 'wolf', 'pressed', 'the', 'latch', 'and', 'the', 'door', 'opened']\n",
      "['he', 'stepped', 'inside', 'went', 'straight', 'to', 'the', 'grandmother', 'bed', 'and', 'ate', 'her', 'up']\n",
      "['then', 'he', 'took', 'her', 'clothes', 'put', 'them', 'on', 'and', 'put', 'her', 'cap', 'on', 'his', 'head']\n",
      "['he', 'got', 'into', 'her', 'bed', 'and', 'pulled', 'the', 'curtains', 'shut']\n",
      "['little', 'red', 'cap', 'had', 'run', 'after', 'flowers', 'and', 'did', 'not', 'continue', 'on', 'her', 'way', 'to', 'grandmother', 'until', 'she', 'had', 'gathered', 'all', 'that', 'she', 'could', 'carry']\n",
      "['when', 'she', 'arrived', 'she', 'found', 'to', 'her', 'surprise', 'that', 'the', 'door', 'was', 'open']\n",
      "['she', 'walked', 'into', 'the', 'parlor', 'and', 'everything', 'looked', 'so', 'strange', 'that', 'she', 'thought', 'oh', 'my', 'god', 'why', 'am', 'so', 'afraid', 'usually', 'like', 'it', 'at', 'grandmother']\n",
      "['then', 'she', 'went', 'to', 'the', 'bed', 'and', 'pulled', 'back', 'the', 'curtains']\n",
      "['grandmother', 'was', 'lying', 'there', 'with', 'her', 'cap', 'pulled', 'down', 'over', 'her', 'face', 'and', 'looking', 'very', 'strange']\n",
      "['oh', 'grandmother', 'what', 'big', 'ears', 'you', 'have', 'all', 'the', 'better', 'to', 'hear', 'you', 'with']\n",
      "['oh', 'grandmother', 'what', 'big', 'eyes', 'you', 'have', 'all', 'the', 'better', 'to', 'see', 'you', 'with']\n",
      "['oh', 'grandmother', 'what', 'big', 'hands', 'you', 'have', 'all', 'the', 'better', 'to', 'grab', 'you', 'with', 'oh', 'grandmother', 'what', 'horribly', 'big', 'mouth', 'you', 'have', 'all', 'the', 'better', 'to', 'eat', 'you', 'with', 'and', 'with', 'that', 'he', 'jumped', 'out', 'of', 'bed', 'jumped', 'on', 'top', 'of', 'poor', 'little', 'red', 'cap', 'and', 'ate', 'her', 'up']\n",
      "['as', 'soon', 'as', 'the', 'wolf', 'had', 'finished', 'this', 'tasty', 'bite', 'he', 'climbed', 'back', 'into', 'bed', 'fell', 'asleep', 'and', 'began', 'to', 'snore', 'very', 'loudly']\n",
      "['huntsman', 'was', 'just', 'passing', 'by']\n",
      "['he', 'thought', 'it', 'strange', 'that', 'the', 'old', 'woman', 'was', 'snoring', 'so', 'loudly', 'so', 'he', 'decided', 'to', 'take', 'look']\n",
      "['he', 'stepped', 'inside', 'and', 'in', 'the', 'bed', 'there', 'lay', 'the', 'wolf', 'that', 'he', 'had', 'been', 'hunting', 'for', 'such', 'long', 'time']\n",
      "['he', 'has', 'eaten', 'the', 'grandmother', 'but', 'perhaps', 'she', 'still', 'can', 'be', 'saved']\n",
      "['won', 'shoot', 'him', 'thought', 'the', 'huntsman']\n",
      "['so', 'he', 'took', 'pair', 'of', 'scissors', 'and', 'cut', 'open', 'his', 'belly']\n",
      "['he', 'had', 'cut', 'only', 'few', 'strokes', 'when', 'he', 'saw', 'the', 'red', 'cap', 'shining', 'through']\n",
      "['he', 'cut', 'little', 'more', 'and', 'the', 'girl', 'jumped', 'out', 'and', 'cried', 'oh', 'was', 'so', 'frightened', 'it', 'was', 'so', 'dark', 'inside', 'the', 'wolf', 'body', 'and', 'then', 'the', 'grandmother', 'came', 'out', 'alive', 'as', 'well']\n",
      "['then', 'little', 'red', 'cap', 'fetched', 'some', 'large', 'heavy', 'stones']\n",
      "['they', 'filled', 'the', 'wolf', 'body', 'with', 'them', 'and', 'when', 'he', 'woke', 'up', 'and', 'tried', 'to', 'run', 'away', 'the', 'stones', 'were', 'so', 'heavy', 'that', 'he', 'fell', 'down', 'dead']\n",
      "['the', 'three', 'of', 'them', 'were', 'happy']\n",
      "['the', 'huntsman', 'took', 'the', 'wolf', 'pelt']\n",
      "['the', 'grandmother', 'ate', 'the', 'cake', 'and', 'drank', 'the', 'wine', 'that', 'little', 'red', 'cap', 'had', 'brought']\n",
      "['and', 'little', 'red', 'cap', 'thought', 'to', 'herself', 'as', 'long', 'as', 'live', 'will', 'never', 'leave', 'the', 'path', 'and', 'run', 'off', 'into', 'the', 'woods', 'by', 'myself', 'if', 'mother', 'tells', 'me', 'not', 'to']\n",
      "['they', 'also', 'tell', 'how', 'little', 'red', 'cap', 'was', 'taking', 'some', 'baked', 'things', 'to', 'her', 'grandmother', 'another', 'time', 'when', 'another', 'wolf', 'spoke', 'to', 'her', 'and', 'wanted', 'her', 'to', 'leave', 'the', 'path']\n",
      "['but', 'little', 'red', 'cap', 'took', 'care', 'and', 'went', 'straight', 'to', 'grandmother']\n",
      "['she', 'told', 'her', 'that', 'she', 'had', 'seen', 'the', 'wolf', 'and', 'that', 'he', 'had', 'wished', 'her', 'good', 'day', 'but', 'had', 'stared', 'at', 'her', 'in', 'wicked', 'manner']\n",
      "['if', 'we', 'hadn', 'been', 'on', 'public', 'road', 'he', 'would', 'have', 'eaten', 'me', 'up', 'she', 'said']\n",
      "['come', 'said', 'the', 'grandmother']\n",
      "['let', 'lock', 'the', 'door', 'so', 'he', 'can', 'get', 'in']\n",
      "['soon', 'afterward', 'the', 'wolf', 'knocked', 'on', 'the', 'door', 'and', 'called', 'out', 'open', 'up', 'grandmother']\n",
      "['it', 'little', 'red', 'cap', 'and', 'bringing', 'you', 'some', 'baked', 'things']\n",
      "['they', 'remained', 'silent', 'and', 'did', 'not', 'open', 'the', 'door']\n",
      "['the', 'wicked', 'one', 'walked', 'around', 'the', 'house', 'several', 'times', 'and', 'finally', 'jumped', 'onto', 'the', 'roof']\n",
      "['he', 'wanted', 'to', 'wait', 'until', 'little', 'red', 'cap', 'went', 'home', 'that', 'evening', 'then', 'follow', 'her', 'and', 'eat', 'her', 'up', 'in', 'the', 'darkness']\n",
      "['but', 'the', 'grandmother', 'saw', 'what', 'he', 'was', 'up', 'to']\n",
      "['there', 'was', 'large', 'stone', 'trough', 'in', 'front', 'of', 'the', 'house']\n",
      "['fetch', 'bucket', 'little', 'red', 'cap', 'she', 'said']\n",
      "['yesterday', 'cooked', 'some', 'sausage']\n",
      "['carry', 'the', 'water', 'that', 'boiled', 'them', 'with', 'to', 'the', 'trough']\n",
      "['little', 'red', 'cap', 'carried', 'water', 'until', 'the', 'large', 'large', 'trough', 'was', 'clear', 'full']\n",
      "['the', 'smell', 'of', 'sausage', 'arose', 'into', 'the', 'wolf', 'nose']\n",
      "['he', 'sniffed', 'and', 'looked', 'down', 'stretching', 'his', 'neck', 'so', 'long', 'that', 'he', 'could', 'no', 'longer', 'hold', 'himself', 'and', 'he', 'began', 'to', 'slide']\n",
      "['he', 'slid', 'off', 'the', 'roof', 'fell', 'into', 'the', 'trough', 'and', 'drowned']\n",
      "['and', 'little', 'red', 'cap', 'returned', 'home', 'happily', 'and', 'safely']\n",
      "['source', 'rothkappchen', 'kinder', 'und', 'hausmarchen', 'st', 'ed']\n",
      "['berlin']\n",
      "['no']\n",
      "['pp']\n",
      "[]\n",
      "['translated', 'by']\n",
      "[]\n",
      "['ashliman']\n",
      "['the', 'grimms', 'source', 'for', 'the', 'first', 'variant', 'the', 'main', 'story', 'was', 'jeanette', 'hassenpflug']\n",
      "['marie', 'hassenpflug', 'provided', 'them', 'with', 'the', 'second', 'variant', 'the', 'concluding', 'episode', 'introduced', 'with', 'the', 'sentence', 'they', 'also', 'tell', 'how', 'little', 'red', 'cap', 'was', 'taking', 'some', 'baked', 'things', 'to', 'her', 'grandmother', 'another', 'time']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['the', 'german', 'title', 'of', 'this', 'tale', 'is', 'rotkappchen', 'rothkappchen', 'in', 'the', 'nineteenth', 'century', 'spelling', 'of', 'the', 'grimm', 'brothers']\n",
      "['link', 'to', 'an', 'english', 'translation', 'of', 'the', 'grimms', 'final', 'version', 'edition', 'of', 'of', 'little', 'red', 'cap']\n",
      "['link', 'to', 'the', 'german', 'text', 'of', 'the', 'grimms', 'final', 'version', 'rothkappchen', 'kinder', 'und', 'hausmarchen', 'gesammelt', 'durch', 'die', 'bruder', 'grimm', 'th', 'edition', 'vol']\n",
      "['gottingen', 'verlag', 'der', 'dieterichschen', 'buchhandlung', 'no']\n",
      "['pp']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "  \n",
    "#  прочитать текстовый файл как объект\n",
    "doc = open('Little_Red_Cap_ Jacob_and_Wilhelm_Grimm.txt', encoding ='utf-8')\n",
    "  \n",
    "# предварительная обработка файла для получения списка токенов\n",
    "tokenized = []\n",
    "for sentence in doc.read().split('.'):\n",
    "    # функция simple_preprocess возвращает список слов каждого предложения\n",
    "    tokenized.append(simple_preprocess(sentence, deacc = True))\n",
    "  \n",
    "for i in tokenized:\n",
    "    print(i)\n",
    "doc.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyinflect чтобы изменять слова (времена глагола, степени прилагательных, число множ/ед)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'examples'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyinflect\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens = nlp('This is an example of xxtest.')\n",
    "tokens[3]._.inflect('NNS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "was\n",
      "were\n",
      "was\n",
      "None\n",
      "None\n",
      "None\n",
      "exampled\n",
      "exampled\n",
      "exampled\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokens)):\n",
    "    # тут условие if проверка на часть речи\n",
    "    for j in range(0, 3):\n",
    "        print(tokens[i]._.inflect('VBD', form_num=j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'were'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1]._.inflect('VBD', form_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxtesting'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[5]._.inflect('VBG', inflect_oov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mtagsets\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('tagsets')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mhelp/tagsets/PY3/upenn_tagset.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/Sergey/nltk_data'\n    - '/Users/Sergey/opt/anaconda3/nltk_data'\n    - '/Users/Sergey/opt/anaconda3/share/nltk_data'\n    - '/Users/Sergey/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nltk\u001b[39m.\u001b[39;49mhelp\u001b[39m.\u001b[39;49mupenn_tagset()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/help.py:27\u001b[0m, in \u001b[0;36mupenn_tagset\u001b[0;34m(tagpattern)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupenn_tagset\u001b[39m(tagpattern\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 27\u001b[0m     _format_tagset(\u001b[39m\"\u001b[39;49m\u001b[39mupenn_tagset\u001b[39;49m\u001b[39m\"\u001b[39;49m, tagpattern)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/help.py:46\u001b[0m, in \u001b[0;36m_format_tagset\u001b[0;34m(tagset, tagpattern)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_format_tagset\u001b[39m(tagset, tagpattern\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 46\u001b[0m     tagdict \u001b[39m=\u001b[39m load(\u001b[39m\"\u001b[39;49m\u001b[39mhelp/tagsets/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m tagset \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tagpattern:\n\u001b[1;32m     48\u001b[0m         _print_entries(\u001b[39msorted\u001b[39m(tagdict), tagdict)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<<Loading \u001b[39m\u001b[39m{\u001b[39;00mresource_url\u001b[39m}\u001b[39;00m\u001b[39m>>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[39m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[39m=\u001b[39m _open(resource_url)\n\u001b[1;32m    752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[39m=\u001b[39m opened_resource\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[39m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnltk\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, path \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[39melif\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[39m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mopen()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtagsets\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('tagsets')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mhelp/tagsets/PY3/upenn_tagset.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/Sergey/nltk_data'\n    - '/Users/Sergey/opt/anaconda3/nltk_data'\n    - '/Users/Sergey/opt/anaconda3/share/nltk_data'\n    - '/Users/Sergey/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
